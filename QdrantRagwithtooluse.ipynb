{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beaab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "qdrant_tool_calling_rag.py\n",
    "Tool-Calling RAG with Qdrant and comprehensive nanosecond latency instrumentation.\n",
    "(Adjusted/fixed indentation, minor bookkeeping, and removed stray text)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any, Tuple, Optional, Callable\n",
    "\n",
    "import pdfplumber\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_groq import ChatGroq\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "PDF_PATH = \"Data/ECHOES OF HER LOVE.pdf\"\n",
    "COLLECTION = \"rag_collection\"\n",
    "DIM = 384\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"‚ùå ERROR: Set GROQ_API_KEY environment variable!\")\n",
    "    # note: keep going if you want to debug offline, but in original script you exit here.\n",
    "    # sys.exit(1)\n",
    "\n",
    "# =========================================================\n",
    "# LATENCY UTILITIES\n",
    "# =========================================================\n",
    "def format_time_ns(ns: int) -> str:\n",
    "    \"\"\"Return human-readable representation of nanoseconds.\"\"\"\n",
    "    if ns < 1_000:\n",
    "        return f\"{ns} ns\"\n",
    "    if ns < 1_000_000:\n",
    "        return f\"{ns/1_000:.3f} ¬µs ({ns} ns)\"\n",
    "    if ns < 1_000_000_000:\n",
    "        return f\"{ns/1_000_000:.3f} ms ({ns} ns)\"\n",
    "    return f\"{ns/1_000_000_000:.3f} s ({ns} ns)\"\n",
    "\n",
    "def timed_call(fn, *args, **kwargs):\n",
    "    \"\"\"Call fn(*args, **kwargs) and return (result, elapsed_ns).\"\"\"\n",
    "    start = time.time_ns()\n",
    "    result = fn(*args, **kwargs)\n",
    "    elapsed = time.time_ns() - start\n",
    "    return result, elapsed\n",
    "\n",
    "def timer_ns(func):\n",
    "    \"\"\"Decorator that prints elapsed ns and stores last_elapsed_ns on wrapper.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time_ns()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.time_ns() - start\n",
    "        print(f\"‚è±Ô∏è  {func.__name__} time: {format_time_ns(elapsed)}\")\n",
    "        wrapper.last_elapsed_ns = elapsed\n",
    "        return result\n",
    "    wrapper.last_elapsed_ns = None\n",
    "    return wrapper\n",
    "\n",
    "class LatencyReport:\n",
    "    \"\"\"Aggregates and reports latency metrics\"\"\"\n",
    "    def __init__(self):\n",
    "        self.store = defaultdict(list)\n",
    "    \n",
    "    def add(self, component: str, ns: int):\n",
    "        self.store[component].append(ns)\n",
    "    \n",
    "    def summary(self) -> Dict:\n",
    "        out = {}\n",
    "        for comp, vals in self.store.items():\n",
    "            total = sum(vals)\n",
    "            out[comp] = {\n",
    "                \"count\": len(vals),\n",
    "                \"total_ns\": total,\n",
    "                \"avg_ns\": total // len(vals) if vals else 0,\n",
    "                \"min_ns\": min(vals) if vals else 0,\n",
    "                \"max_ns\": max(vals) if vals else 0\n",
    "            }\n",
    "        return out\n",
    "    \n",
    "    def pretty_print(self):\n",
    "        s = self.summary()\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"LATENCY SUMMARY (nanoseconds)\")\n",
    "        print(\"=\"*70)\n",
    "        for comp, stats in sorted(s.items(), key=lambda p: p[0]):\n",
    "            print(f\"\\nüìä Component: {comp}\")\n",
    "            print(f\"   Count:     {stats['count']}\")\n",
    "            print(f\"   Total:     {format_time_ns(stats['total_ns'])}\")\n",
    "            print(f\"   Average:   {format_time_ns(stats['avg_ns'])}\")\n",
    "            print(f\"   Min:       {format_time_ns(stats['min_ns'])}\")\n",
    "            print(f\"   Max:       {format_time_ns(stats['max_ns'])}\")\n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "latency_report = LatencyReport()\n",
    "\n",
    "# =========================================================\n",
    "# LOAD PDF WITH TIMING\n",
    "# =========================================================\n",
    "@timer_ns\n",
    "def load_pdf(path: str) -> str:\n",
    "    \"\"\"Load PDF with per-page timing\"\"\"\n",
    "    print(f\"üìÑ Loading PDF: {path}\")\n",
    "    text = \"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö†Ô∏è  PDF not found at path: {path}\")\n",
    "        return \"\"\n",
    "    \n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        pages = pdf.pages\n",
    "        for i, p in enumerate(pages):\n",
    "            start_ns = time.time_ns()\n",
    "            t = p.extract_text() or \"\"\n",
    "            elapsed = time.time_ns() - start_ns\n",
    "            latency_report.add(\"pdf_page_extract\", elapsed)\n",
    "            text += t + \"\\n\"\n",
    "    \n",
    "    print(f\"‚úÖ Loaded PDF: {len(text)} characters from {len(pages)} pages\")\n",
    "    return text\n",
    "\n",
    "# =========================================================\n",
    "# CHUNK TEXT WITH TIMING\n",
    "# =========================================================\n",
    "@timer_ns\n",
    "def chunk_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 100) -> List[str]:\n",
    "    \"\"\"Chunk text with timing\"\"\"\n",
    "    print(f\"‚úÇÔ∏è  Chunking text...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    print(f\"‚úÖ Created {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "# =========================================================\n",
    "# LOAD EMBEDDINGS WITH TIMING\n",
    "# =========================================================\n",
    "@timer_ns\n",
    "def load_embeddings(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> SentenceTransformer:\n",
    "    \"\"\"Load embedding model with timing\"\"\"\n",
    "    print(f\"üî¢ Loading embeddings model: {model_name}\")\n",
    "    embedder = SentenceTransformer(model_name)\n",
    "    print(f\"‚úÖ Embeddings model loaded\")\n",
    "    return embedder\n",
    "\n",
    "# =========================================================\n",
    "# INIT QDRANT WITH TIMING\n",
    "# =========================================================\n",
    "@timer_ns\n",
    "def init_qdrant(collection_name: str = COLLECTION, dim: int = DIM) -> QdrantClient:\n",
    "    \"\"\"Initialize Qdrant with timing\"\"\"\n",
    "    print(f\"üóÉÔ∏è  Initializing Qdrant in-memory DB\")\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    # note: change as-needed for your environment; some Qdrant clients don't support \":memory:\"\n",
    "    qdrant = QdrantClient(\":memory:\")\n",
    "    init_time = time.time_ns() - start\n",
    "    latency_report.add(\"qdrant_client_init\", init_time)\n",
    "    \n",
    "    # Remove previous collection if exists\n",
    "    if qdrant.collection_exists(collection_name):\n",
    "        start = time.time_ns()\n",
    "        qdrant.delete_collection(collection_name)\n",
    "        delete_time = time.time_ns() - start\n",
    "        latency_report.add(\"qdrant_delete_collection\", delete_time)\n",
    "    \n",
    "    # Create collection\n",
    "    start = time.time_ns()\n",
    "    qdrant.create_collection(\n",
    "        collection_name,\n",
    "        vectors_config=VectorParams(size=dim, distance=Distance.COSINE)\n",
    "    )\n",
    "    create_time = time.time_ns() - start\n",
    "    latency_report.add(\"qdrant_create_collection\", create_time)\n",
    "    \n",
    "    print(f\"‚úÖ Qdrant collection '{collection_name}' ready\")\n",
    "    return qdrant\n",
    "\n",
    "# =========================================================\n",
    "# INSERT CHUNKS WITH TIMING\n",
    "# =========================================================\n",
    "@timer_ns\n",
    "def insert_chunks(qdrant: QdrantClient, embedder: SentenceTransformer, \n",
    "                  chunks: List[str], collection_name: str = COLLECTION) -> None:\n",
    "    \"\"\"Insert chunks into Qdrant with detailed timing\"\"\"\n",
    "    print(f\"‚¨ÜÔ∏è  Inserting {len(chunks)} chunks into Qdrant...\")\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"‚ö†Ô∏è  No chunks to insert.\")\n",
    "        return\n",
    "    \n",
    "    # Encode chunks (batch embedding)\n",
    "    print(f\"   üî¢ Encoding {len(chunks)} chunks...\")\n",
    "    start = time.time_ns()\n",
    "    vectors = embedder.encode(chunks, show_progress_bar=False)\n",
    "    encode_time = time.time_ns() - start\n",
    "    latency_report.add(\"embedding_encode_batch\", encode_time)\n",
    "    print(f\"   ‚úÖ Encoded in {format_time_ns(encode_time)}\")\n",
    "    \n",
    "    # Create points\n",
    "    print(f\"   üì¶ Creating point structures...\")\n",
    "    start = time.time_ns()\n",
    "    points = [\n",
    "        PointStruct(\n",
    "            id=i,\n",
    "            vector=vectors[i].tolist() if hasattr(vectors[i], \"tolist\") else list(vectors[i]),\n",
    "            payload={\"text\": chunks[i], \"chunk_id\": i}\n",
    "        )\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "    point_creation_time = time.time_ns() - start\n",
    "    latency_report.add(\"qdrant_point_creation\", point_creation_time)\n",
    "    print(f\"   ‚úÖ Points created in {format_time_ns(point_creation_time)}\")\n",
    "    \n",
    "    # Upsert to Qdrant\n",
    "    print(f\"   üíæ Upserting to Qdrant...\")\n",
    "    start = time.time_ns()\n",
    "    qdrant.upsert(collection_name=collection_name, points=points)\n",
    "    upsert_time = time.time_ns() - start\n",
    "    latency_report.add(\"qdrant_upsert\", upsert_time)\n",
    "    print(f\"   ‚úÖ Upserted in {format_time_ns(upsert_time)}\")\n",
    "    \n",
    "    print(f\"‚úÖ All chunks inserted successfully!\")\n",
    "\n",
    "# =========================================================\n",
    "# SEARCH QDRANT WITH TIMING\n",
    "# =========================================================\n",
    "def search_qdrant(qdrant: QdrantClient, embedder: SentenceTransformer, \n",
    "                  query: str, limit: int = 4, collection_name: str = COLLECTION) -> Tuple[List[str], int]:\n",
    "    \"\"\"Search Qdrant with timing\"\"\"\n",
    "    \n",
    "    if not query:\n",
    "        return [], 0\n",
    "    \n",
    "    # Encode query\n",
    "    start = time.time_ns()\n",
    "    qvecs = embedder.encode([query])\n",
    "    qvec = qvecs[0]\n",
    "    encode_time = time.time_ns() - start\n",
    "    latency_report.add(\"query_embedding\", encode_time)\n",
    "    \n",
    "    # Query Qdrant\n",
    "    start = time.time_ns()\n",
    "    response = qdrant.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qvec.tolist() if hasattr(qvec, \"tolist\") else list(qvec),\n",
    "        limit=limit\n",
    "    )\n",
    "    search_time = time.time_ns() - start\n",
    "    latency_report.add(\"qdrant_search\", search_time)\n",
    "    \n",
    "    # Extract texts\n",
    "    hits = [p.payload.get(\"text\", \"\") for p in response.points]\n",
    "    \n",
    "    total_time = encode_time + search_time\n",
    "    \n",
    "    return hits, total_time\n",
    "\n",
    "# =========================================================\n",
    "# TOOL DEFINITIONS\n",
    "# (unchanged from original; kept for brevity)\n",
    "# =========================================================\n",
    "class Tool:\n",
    "    \"\"\"Base class for tools\"\"\"\n",
    "    def __init__(self, name: str, description: str, parameters: List[str]):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def execute(self, **kwargs) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"parameters\": self.parameters\n",
    "        }\n",
    "\n",
    "class DocumentSearchTool(Tool):\n",
    "    def __init__(self, qdrant: QdrantClient, embedder: SentenceTransformer, collection: str):\n",
    "        super().__init__(\n",
    "            name=\"document_search\",\n",
    "            description=\"Search the document database for relevant information. Use this when you need to find specific information from the document.\",\n",
    "            parameters=[\"query: str - The search query\"]\n",
    "        )\n",
    "        self.qdrant = qdrant\n",
    "        self.embedder = embedder\n",
    "        self.collection = collection\n",
    "    \n",
    "    def execute(self, query: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        \n",
    "        hits, search_time = search_qdrant(self.qdrant, self.embedder, query, 4, self.collection)\n",
    "        result_text = \"\\n\\n\".join(hits)\n",
    "        \n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"tool_document_search\", elapsed)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"tool\": \"document_search\",\n",
    "            \"result\": result_text,\n",
    "            \"num_results\": len(hits),\n",
    "            \"elapsed_ns\": elapsed\n",
    "        }\n",
    "\n",
    "class CalculatorTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"calculator\",\n",
    "            description=\"Perform mathematical calculations. Supports basic operations (+, -, *, /) and functions (sqrt, pow, sin, cos, etc.).\",\n",
    "            parameters=[\"expression: str - Mathematical expression to evaluate (e.g., '2+2', 'sqrt(16)', 'pow(2,3)')\"]\n",
    "        )\n",
    "    \n",
    "    def execute(self, expression: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        \n",
    "        try:\n",
    "            allowed = {k: v for k, v in math.__dict__.items() if not k.startswith(\"__\")}\n",
    "            result = eval(expression, {\"__builtins__\": {}}, allowed)\n",
    "            \n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_calculator\", elapsed)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"tool\": \"calculator\",\n",
    "                \"result\": f\"Calculation result: {result}\",\n",
    "                \"value\": result,\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"tool\": \"calculator\",\n",
    "                \"result\": f\"Calculation error: {str(e)}\",\n",
    "                \"error\": str(e),\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "\n",
    "class SentimentAnalyzerTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"sentiment_analyzer\",\n",
    "            description=\"Analyze the sentiment of text. Returns POSITIVE, NEGATIVE, or NEUTRAL with a confidence score.\",\n",
    "            parameters=[\"text: str - Text to analyze for sentiment\"]\n",
    "        )\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def execute(self, text: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        \n",
    "        scores = self.analyzer.polarity_scores(text)\n",
    "        compound = scores['compound']\n",
    "        \n",
    "        if compound >= 0.05:\n",
    "            label = \"POSITIVE\"\n",
    "        elif compound <= -0.05:\n",
    "            label = \"NEGATIVE\"\n",
    "        else:\n",
    "            label = \"NEUTRAL\"\n",
    "        \n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"tool_sentiment\", elapsed)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"tool\": \"sentiment_analyzer\",\n",
    "            \"result\": f\"Sentiment: {label} (score: {compound:.3f})\",\n",
    "            \"label\": label,\n",
    "            \"compound\": compound,\n",
    "            \"elapsed_ns\": elapsed\n",
    "        }\n",
    "\n",
    "class SummarizerTool(Tool):\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\n",
    "            name=\"summarizer\",\n",
    "            description=\"Summarize long text into a concise summary. Useful for condensing large amounts of information.\",\n",
    "            parameters=[\"text: str - Text to summarize\"]\n",
    "        )\n",
    "        self.llm = llm\n",
    "    \n",
    "    def execute(self, text: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        \n",
    "        try:\n",
    "            prompt = f\"\"\"Provide a concise 2-3 sentence summary of the following text:\n",
    "\n",
    "{text[:2000]}\n",
    "\n",
    "Summary:\"\"\"\n",
    "            \n",
    "            resp = self.llm.invoke(prompt)\n",
    "            summary = resp.content if hasattr(resp, \"content\") else str(resp)\n",
    "            \n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_summarizer\", elapsed)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"tool\": \"summarizer\",\n",
    "                \"result\": summary,\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"tool\": \"summarizer\",\n",
    "                \"result\": f\"Summarization error: {str(e)}\",\n",
    "                \"error\": str(e),\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "\n",
    "# =========================================================\n",
    "# TOOL-CALLING RAG SYSTEM\n",
    "# (kept mostly as in your original)\n",
    "# =========================================================\n",
    "class ToolCallingRAG:\n",
    "    def __init__(self, llm, tools: List[Tool], max_tool_calls: int = 5):\n",
    "        self.llm = llm\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.max_tool_calls = max_tool_calls\n",
    "    \n",
    "    def _format_tools_for_prompt(self) -> str:\n",
    "        tool_descriptions = []\n",
    "        for name, tool in self.tools.items():\n",
    "            params = \", \".join(tool.parameters)\n",
    "            tool_descriptions.append(f\"- {name}: {tool.description}\\n  Parameters: {params}\")\n",
    "        return \"\\n\".join(tool_descriptions)\n",
    "    \n",
    "    def _llm_invoke(self, prompt: str, label: str) -> Tuple[str, int]:\n",
    "        start = time.time_ns()\n",
    "        resp = self.llm.invoke(prompt)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(f\"llm_{label}\", elapsed)\n",
    "        \n",
    "        content = resp.content if hasattr(resp, \"content\") else str(resp)\n",
    "        return content, elapsed\n",
    "    \n",
    "    def _parse_tool_call(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        pattern = r'USE_TOOL:\\s*(\\w+)\\s*\\((.*?)\\)'\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        if not match:\n",
    "            return None\n",
    "        \n",
    "        tool_name = match.group(1).strip()\n",
    "        args_str = match.group(2).strip()\n",
    "        \n",
    "        args = {}\n",
    "        if args_str:\n",
    "            arg_pattern = r'(\\w+)\\s*=\\s*[\"\\']([^\"\\']*)[\"\\']'\n",
    "            for arg_match in re.finditer(arg_pattern, args_str):\n",
    "                key = arg_match.group(1)\n",
    "                value = arg_match.group(2)\n",
    "                args[key] = value\n",
    "        \n",
    "        return {\"tool\": tool_name, \"args\": args}\n",
    "    \n",
    "    def _execute_tool(self, tool_name: str, args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        if tool_name not in self.tools:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"tool\": tool_name,\n",
    "                \"result\": f\"Tool '{tool_name}' not found\",\n",
    "                \"error\": f\"Unknown tool: {tool_name}\",\n",
    "                \"elapsed_ns\": 0\n",
    "            }\n",
    "        \n",
    "        tool = self.tools[tool_name]\n",
    "        print(f\"      üîß Executing tool: {tool_name}\")\n",
    "        print(f\"         Args: {args}\")\n",
    "        \n",
    "        result = tool.execute(**args)\n",
    "        \n",
    "        if result.get(\"success\"):\n",
    "            print(f\"      ‚úÖ Tool succeeded in {format_time_ns(result.get('elapsed_ns', 0))}\")\n",
    "        else:\n",
    "            print(f\"      ‚ùå Tool failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def query(self, question: str) -> Dict[str, Any]:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üîß TOOL-CALLING RAG QUERY PROCESSING\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"‚ùì Question: {question}\\n\")\n",
    "        \n",
    "        overall_start = time.time_ns()\n",
    "        \n",
    "        tools_description = self._format_tools_for_prompt()\n",
    "        \n",
    "        system_prompt = f\"\"\"You are an intelligent assistant with access to tools. Answer the question by using the available tools.\n",
    "\n",
    "Available Tools:\n",
    "{tools_description}\n",
    "\n",
    "To use a tool, write:\n",
    "USE_TOOL: tool_name(param1=\"value1\", param2=\"value2\")\n",
    "\n",
    "You can use multiple tools. After each tool use, I will provide the result, and you can decide to use another tool or provide the final answer.\n",
    "\n",
    "When you have enough information, provide your final answer starting with \"FINAL ANSWER:\"\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "What tools do you need to use?\"\"\"\n",
    "        \n",
    "        conversation_history = []\n",
    "        tool_results = []\n",
    "        tool_call_count = 0\n",
    "        \n",
    "        current_prompt = system_prompt\n",
    "        \n",
    "        while tool_call_count < self.max_tool_calls:\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"üîÑ Tool-Calling Step {tool_call_count + 1}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            step_start = time.time_ns()\n",
    "            \n",
    "            response, llm_time = self._llm_invoke(current_prompt, f\"tool_step_{tool_call_count + 1}\")\n",
    "            print(f\"   üß† LLM Response: {response[:200]}...\")\n",
    "            \n",
    "            if \"FINAL ANSWER:\" in response.upper():\n",
    "                final_match = re.search(r'FINAL ANSWER:\\s*(.+)', response, re.IGNORECASE | re.DOTALL)\n",
    "                if final_match:\n",
    "                    answer = final_match.group(1).strip()\n",
    "                    print(f\"   ‚úÖ Final answer provided\")\n",
    "                    \n",
    "                    step_elapsed = time.time_ns() - step_start\n",
    "                    latency_report.add(\"tool_calling_step\", step_elapsed)\n",
    "                    break\n",
    "            \n",
    "            tool_call = self._parse_tool_call(response)\n",
    "            \n",
    "            if tool_call:\n",
    "                tool_call_count += 1\n",
    "                tool_name = tool_call[\"tool\"]\n",
    "                tool_args = tool_call[\"args\"]\n",
    "                \n",
    "                print(f\"   üéØ Tool Call: {tool_name}\")\n",
    "                \n",
    "                result = self._execute_tool(tool_name, tool_args)\n",
    "                tool_results.append(result)\n",
    "                \n",
    "                tool_output = result.get(\"result\", \"No result\")\n",
    "                current_prompt = f\"\"\"Previous tool used: {tool_name}\n",
    "Tool result: {tool_output}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "You can use another tool or provide the FINAL ANSWER: [your answer]\n",
    "\n",
    "What's next?\"\"\"\n",
    "                \n",
    "                step_elapsed = time.time_ns() - step_start\n",
    "                latency_report.add(\"tool_calling_step\", step_elapsed)\n",
    "                print(f\"   ‚è±Ô∏è Step time: {format_time_ns(step_elapsed)}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No tool call detected\")\n",
    "                \n",
    "                if len(response.strip()) > 50:\n",
    "                    answer = response.strip()\n",
    "                    break\n",
    "                \n",
    "                current_prompt = f\"\"\"You need to either:\n",
    "1. USE_TOOL: tool_name(param=\"value\") to use a tool\n",
    "2. Provide FINAL ANSWER: [your answer]\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please respond:\"\"\"\n",
    "                \n",
    "                step_elapsed = time.time_ns() - step_start\n",
    "                latency_report.add(\"tool_calling_step\", step_elapsed)\n",
    "        \n",
    "        if tool_call_count >= self.max_tool_calls and 'answer' not in locals():\n",
    "            print(f\"\\n   ‚ö†Ô∏è Max tool calls reached\")\n",
    "            if tool_results:\n",
    "                last_result = tool_results[-1].get(\"result\", \"No answer generated\")\n",
    "                answer = f\"Based on tool results: {last_result[:500]}\"\n",
    "            else:\n",
    "                answer = \"Unable to determine answer\"\n",
    "        \n",
    "        total_query_ns = time.time_ns() - overall_start\n",
    "        latency_report.add(\"tool_calling_query_total\", total_query_ns)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìä TOOL-CALLING SUMMARY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Tools used: {tool_call_count}\")\n",
    "        print(f\"Total time: {format_time_ns(total_query_ns)}\")\n",
    "        \n",
    "        if tool_results:\n",
    "            print(f\"\\nüîß Tools Executed:\")\n",
    "            for i, tr in enumerate(tool_results, 1):\n",
    "                print(f\"   {i}. {tr['tool']} - {format_time_ns(tr.get('elapsed_ns', 0))}\")\n",
    "        \n",
    "        print(f\"\\nüí¨ FINAL ANSWER:\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        print(answer[:800])\n",
    "        if len(answer) > 800:\n",
    "            print(\"...\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'tool_calls': tool_call_count,\n",
    "            'tool_results': tool_results,\n",
    "            'total_query_ns': total_query_ns\n",
    "        }\n",
    "\n",
    "# =========================================================\n",
    "# VADER SENTIMENT BENCHMARK\n",
    "# =========================================================\n",
    "class VaderSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def analyze(self, text: str) -> Dict[str, Any]:\n",
    "        scores = self.analyzer.polarity_scores(text)\n",
    "        compound = scores['compound']\n",
    "        \n",
    "        if compound >= 0.05:\n",
    "            label = \"POSITIVE\"\n",
    "            percentage = round((compound + 1) * 50, 2)\n",
    "        elif compound <= -0.05:\n",
    "            label = \"NEGATIVE\"\n",
    "            percentage = round((1 - abs(compound)) * 50, 2)\n",
    "        else:\n",
    "            label = \"NEUTRAL\"\n",
    "            percentage = round(50 + (compound * 50), 2)\n",
    "        \n",
    "        return {\n",
    "            'label': label,\n",
    "            'percentage': percentage,\n",
    "            'compound': compound,\n",
    "            'scores': scores\n",
    "        }\n",
    "\n",
    "def run_sentiment_benchmark(sa: VaderSentimentAnalyzer, examples: List[str], \n",
    "                            target_ns: int = 200_000, run_number: int = 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî• SENTIMENT BENCHMARK RUN #{run_number}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"üéØ TARGET: < {target_ns} ns per analysis\\n\")\n",
    "    \n",
    "    individual_times = []\n",
    "    for i, text in enumerate(examples, 1):\n",
    "        start_ns = time.time_ns()\n",
    "        result = sa.analyze(text)\n",
    "        elapsed_ns = time.time_ns() - start_ns\n",
    "        latency_report.add(\"vader_per_example\", elapsed_ns)\n",
    "        individual_times.append(elapsed_ns)\n",
    "        \n",
    "        status = \"‚úÖ\" if elapsed_ns < target_ns else \"‚ùå\"\n",
    "        print(f\"[{i:2d}] {format_time_ns(elapsed_ns):25s} {status} | {result['label']:8s} | \\\"{text}\\\"\")\n",
    "    \n",
    "    total_ns = sum(individual_times)\n",
    "    avg_ns = total_ns // len(individual_times)\n",
    "    min_ns = min(individual_times)\n",
    "    max_ns = max(individual_times)\n",
    "    under_target = sum(1 for t in individual_times if t < target_ns)\n",
    "    \n",
    "    print(f\"\\nüìä RUN #{run_number} STATISTICS:\")\n",
    "    print(f\"   Total:        {format_time_ns(total_ns)}\")\n",
    "    print(f\"   Average:      {format_time_ns(avg_ns)}\")\n",
    "    print(f\"   Min:          {format_time_ns(min_ns)}\")\n",
    "    print(f\"   Max:          {format_time_ns(max_ns)}\")\n",
    "    print(f\"   < {target_ns}ns: {under_target}/{len(individual_times)} texts\")\n",
    "    \n",
    "    if avg_ns < target_ns:\n",
    "        print(f\"   ‚úÖ TARGET MET!\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  TARGET MISSED\")\n",
    "\n",
    "# =========================================================\n",
    "# MAIN PROGRAM\n",
    "# =========================================================\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîß TOOL-CALLING RAG + FULL LATENCY INSTRUMENTATION\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    \n",
    "    pipeline_start = time.time_ns()\n",
    "    \n",
    "    # Phase 1: Load and prepare data\n",
    "    print(\"üìö PHASE 1: DATA PREPARATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    text, load_time = timed_call(load_pdf, PDF_PATH)\n",
    "    latency_report.add(\"pipeline_pdf_load\", load_time)\n",
    "    \n",
    "    chunks, chunk_time = timed_call(chunk_text, text, 1000, 100)\n",
    "    latency_report.add(\"pipeline_chunking\", chunk_time)\n",
    "    \n",
    "    embedder, embed_time = timed_call(load_embeddings, \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    latency_report.add(\"pipeline_embeddings_load\", embed_time)\n",
    "    \n",
    "    qdrant, qdrant_time = timed_call(init_qdrant, COLLECTION, DIM)\n",
    "    latency_report.add(\"pipeline_qdrant_init\", qdrant_time)\n",
    "    \n",
    "    insert_time_start = time.time_ns()\n",
    "    insert_chunks(qdrant, embedder, chunks, COLLECTION)\n",
    "    insert_time = time.time_ns() - insert_time_start\n",
    "    latency_report.add(\"pipeline_insert_chunks\", insert_time)\n",
    "\n",
    "    # Phase 2: Initialize LLM\n",
    "    print(f\"\\nüìö PHASE 2: LLM INITIALIZATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    llm_start = time.time_ns()\n",
    "    llm = ChatGroq(\n",
    "        model_name=MODEL_NAME,\n",
    "        groq_api_key=GROQ_API_KEY,\n",
    "        temperature=0\n",
    "    )\n",
    "    llm_time = time.time_ns() - llm_start\n",
    "    latency_report.add(\"pipeline_llm_init\", llm_time)\n",
    "    print(f\"‚úÖ LLM initialized in {format_time_ns(llm_time)}\")\n",
    "\n",
    "    # Phase 3: Initialize Tools\n",
    "    print(f\"\\nüìö PHASE 3: TOOL INITIALIZATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    tools = [\n",
    "        DocumentSearchTool(qdrant, embedder, COLLECTION),\n",
    "        CalculatorTool(),\n",
    "        SentimentAnalyzerTool(),\n",
    "        SummarizerTool(llm)\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Available tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"   üîß {tool.name}: {tool.description[:60]}...\")\n",
    "    \n",
    "    # Initialize Tool-Calling RAG\n",
    "    tool_rag = ToolCallingRAG(llm, tools, max_tool_calls=5)\n",
    "    print(f\"\\n‚úÖ Tool-Calling RAG system initialized!\")\n",
    "    \n",
    "    # Phase 4: Run Tool-Calling queries\n",
    "    print(f\"\\nüìö PHASE 4: TOOL-CALLING RAG QUERIES\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    queries = [\n",
    "        \"What are the main themes in this story?\",\n",
    "        \"Calculate the square root of 144 and then search for information about love in the document\",\n",
    "        \"Analyze the sentiment of this text: 'This is a beautiful and touching story'\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for q in queries:\n",
    "        result = tool_rag.query(q)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Phase 5: Sentiment benchmark\n",
    "    print(f\"\\nüìö PHASE 5: VADER SENTIMENT BENCHMARK\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    sa_start = time.time_ns()\n",
    "    sa = VaderSentimentAnalyzer()\n",
    "    sa_init = time.time_ns() - sa_start\n",
    "    latency_report.add(\"vader_init\", sa_init)\n",
    "    print(f\"‚úÖ VADER INIT TIME: {format_time_ns(sa_init)}\\n\")\n",
    "    \n",
    "    examples = [\n",
    "        \"I love this product!\",\n",
    "        \"This is very bad service.\",\n",
    "        \"It's okay, not too good, not too bad.\",\n",
    "        \"Not great, really disappointed\",\n",
    "        \"Amazing experience!\"\n",
    "    ]\n",
    "    \n",
    "    run_sentiment_benchmark(sa, examples, 200_000, 1)\n",
    "    \n",
    "    # Final summary\n",
    "    pipeline_total = time.time_ns() - pipeline_start\n",
    "    latency_report.add(\"pipeline_total\", pipeline_total)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìà PIPELINE SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total pipeline time: {format_time_ns(pipeline_total)}\")\n",
    "    print(f\"Queries executed: {len(queries)}\")\n",
    "    average_query_time = (sum(r['total_query_ns'] for r in results) // len(results)) if results else 0\n",
    "    print(f\"Average query time: {format_time_ns(average_query_time)}\")\n",
    "    \n",
    "    print(f\"\\nüîß Tool Usage Statistics:\")\n",
    "    total_tool_calls = sum(r['tool_calls'] for r in results)\n",
    "    print(f\"   Total tool calls: {total_tool_calls}\")\n",
    "    print(f\"   Average per query: {total_tool_calls / len(results):.1f}\" if results else \"   Average per query: 0\")\n",
    "    \n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"   Query {i}: {r['tool_calls']} tool(s), {format_time_ns(r['total_query_ns'])}\")\n",
    "    \n",
    "    # Detailed latency report\n",
    "    latency_report.pretty_print()\n",
    "    \n",
    "    print(\"‚úÖ PIPELINE COMPLETE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
