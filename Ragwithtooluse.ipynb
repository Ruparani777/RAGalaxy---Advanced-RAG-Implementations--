{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "agentic_rag_tools.py\n",
    "Agentic RAG with Tool Use - LLM decides which tools to use and when.\n",
    "\n",
    "Tools available:\n",
    "- document_search: Search the vector database\n",
    "- calculator: Perform mathematical calculations\n",
    "- sentiment_analyzer: Analyze sentiment of text\n",
    "- web_search_simulator: Simulate web search for general knowledge\n",
    "- document_summary: Get summary of retrieved documents\n",
    "\n",
    "Environment variables needed:\n",
    "    PINECONE_API_KEY, GROQ_API_KEY\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import pdfplumber\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "PDF_PATH = \"Data/ECHOES OF HER LOVE.pdf\"\n",
    "INDEX_NAME = \"pinecone-agentic\"\n",
    "DIM = 384\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
    "\n",
    "if PINECONE_API_KEY is None or GROQ_API_KEY is None:\n",
    "    print(\"ERROR: Set PINECONE_API_KEY and GROQ_API_KEY environment variables\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def format_time_ns(ns: int) -> str:\n",
    "    if ns < 1_000:\n",
    "        return f\"{ns} ns\"\n",
    "    if ns < 1_000_000:\n",
    "        return f\"{ns/1_000:.3f} ¬µs\"\n",
    "    if ns < 1_000_000_000:\n",
    "        return f\"{ns/1_000_000:.3f} ms\"\n",
    "    return f\"{ns/1_000_000_000:.3f} s\"\n",
    "\n",
    "class LatencyReport:\n",
    "    def __init__(self):\n",
    "        self.store = defaultdict(list)\n",
    "    \n",
    "    def add(self, component, ns):\n",
    "        self.store[component].append(ns)\n",
    "    \n",
    "    def pretty_print(self):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"LATENCY SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        for comp, vals in sorted(self.store.items()):\n",
    "            total = sum(vals)\n",
    "            avg = total // len(vals) if vals else 0\n",
    "            print(f\"\\n{comp}:\")\n",
    "            print(f\"  Count: {len(vals)}, Total: {format_time_ns(total)}, Avg: {format_time_ns(avg)}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "latency_report = LatencyReport()\n",
    "\n",
    "# ---------------------------\n",
    "# Tool Definitions\n",
    "# ---------------------------\n",
    "class Tool:\n",
    "    \"\"\"Base class for tools\"\"\"\n",
    "    def __init__(self, name: str, description: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "    \n",
    "    def execute(self, **kwargs) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class DocumentSearchTool(Tool):\n",
    "    def __init__(self, vectorstore):\n",
    "        super().__init__(\n",
    "            name=\"document_search\",\n",
    "            description=\"Search the document database for relevant information. Input: 'query' (string)\"\n",
    "        )\n",
    "        self.vectorstore = vectorstore\n",
    "        self.retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "    \n",
    "    def execute(self, query: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            docs = self.retriever.invoke(query)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_document_search\", elapsed)\n",
    "            \n",
    "            results = []\n",
    "            for doc in docs:\n",
    "                content = getattr(doc, \"page_content\", str(doc))\n",
    "                results.append(content)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": \"\\n\\n\".join(results),\n",
    "                \"num_docs\": len(results),\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\"success\": False, \"error\": str(e), \"elapsed_ns\": elapsed}\n",
    "\n",
    "class CalculatorTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"calculator\",\n",
    "            description=\"Perform mathematical calculations. Input: 'expression' (string, e.g., '2+2', 'sqrt(16)', 'sin(3.14)')\"\n",
    "        )\n",
    "    \n",
    "    def execute(self, expression: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            # Safe eval with math functions\n",
    "            allowed_names = {k: v for k, v in math.__dict__.items() if not k.startswith(\"__\")}\n",
    "            result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_calculator\", elapsed)\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": str(result),\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\"success\": False, \"error\": str(e), \"elapsed_ns\": elapsed}\n",
    "\n",
    "class SentimentAnalyzerTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"sentiment_analyzer\",\n",
    "            description=\"Analyze sentiment of text. Input: 'text' (string)\"\n",
    "        )\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def execute(self, text: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            scores = self.analyzer.polarity_scores(text)\n",
    "            compound = scores['compound']\n",
    "            \n",
    "            if compound >= 0.05:\n",
    "                label = \"POSITIVE\"\n",
    "            elif compound <= -0.05:\n",
    "                label = \"NEGATIVE\"\n",
    "            else:\n",
    "                label = \"NEUTRAL\"\n",
    "            \n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_sentiment\", elapsed)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": f\"Sentiment: {label} (score: {compound:.3f})\",\n",
    "                \"label\": label,\n",
    "                \"compound\": compound,\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\"success\": False, \"error\": str(e), \"elapsed_ns\": elapsed}\n",
    "\n",
    "class WebSearchSimulatorTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"web_search\",\n",
    "            description=\"Search for general knowledge (simulated). Input: 'query' (string)\"\n",
    "        )\n",
    "        # Simulated knowledge base\n",
    "        self.knowledge = {\n",
    "            \"capital of france\": \"Paris is the capital of France.\",\n",
    "            \"population of earth\": \"Earth's population is approximately 8 billion people.\",\n",
    "            \"who invented python\": \"Python was created by Guido van Rossum in 1991.\",\n",
    "            \"speed of light\": \"The speed of light is approximately 299,792,458 meters per second.\",\n",
    "        }\n",
    "    \n",
    "    def execute(self, query: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Simple matching\n",
    "        result = \"No information found.\"\n",
    "        for key, value in self.knowledge.items():\n",
    "            if key in query_lower or any(word in query_lower for word in key.split()):\n",
    "                result = value\n",
    "                break\n",
    "        \n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"tool_web_search\", elapsed)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"result\": result,\n",
    "            \"elapsed_ns\": elapsed\n",
    "        }\n",
    "\n",
    "class DocumentSummaryTool(Tool):\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\n",
    "            name=\"document_summary\",\n",
    "            description=\"Get a summary of document chunks. Input: 'text' (string)\"\n",
    "        )\n",
    "        self.llm = llm\n",
    "    \n",
    "    def execute(self, text: str = \"\", **kwargs) -> Dict[str, Any]:\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            prompt = f\"\"\"Provide a concise summary of the following text in 2-3 sentences:\n",
    "\n",
    "{text[:2000]}\n",
    "\n",
    "Summary:\"\"\"\n",
    "            response = self.llm.invoke(prompt)\n",
    "            content = response.content if hasattr(response, 'content') else str(response)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"tool_summary\", elapsed)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": content,\n",
    "                \"elapsed_ns\": elapsed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            return {\"success\": False, \"error\": str(e), \"elapsed_ns\": elapsed}\n",
    "\n",
    "# ---------------------------\n",
    "# Agentic RAG System\n",
    "# ---------------------------\n",
    "class AgenticRAG:\n",
    "    \"\"\"RAG system where LLM decides which tools to use\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools: List[Tool]):\n",
    "        self.llm = llm\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.tool_descriptions = self._format_tool_descriptions()\n",
    "    \n",
    "    def _format_tool_descriptions(self) -> str:\n",
    "        descriptions = []\n",
    "        for name, tool in self.tools.items():\n",
    "            descriptions.append(f\"- {name}: {tool.description}\")\n",
    "        return \"\\n\".join(descriptions)\n",
    "    \n",
    "    def _parse_tool_call(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Parse tool call from LLM response\"\"\"\n",
    "        # Look for patterns like: USE_TOOL: tool_name(arg1=\"value1\", arg2=\"value2\")\n",
    "        pattern = r'USE_TOOL:\\s*(\\w+)\\s*\\((.*?)\\)'\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        if not match:\n",
    "            return None\n",
    "        \n",
    "        tool_name = match.group(1).strip()\n",
    "        args_str = match.group(2).strip()\n",
    "        \n",
    "        # Parse arguments\n",
    "        args = {}\n",
    "        if args_str:\n",
    "            # Simple parsing: key=\"value\" or key='value'\n",
    "            arg_pattern = r'(\\w+)\\s*=\\s*[\"\\']([^\"\\']*)[\"\\']'\n",
    "            for arg_match in re.finditer(arg_pattern, args_str):\n",
    "                key = arg_match.group(1)\n",
    "                value = arg_match.group(2)\n",
    "                args[key] = value\n",
    "        \n",
    "        return {\"tool\": tool_name, \"args\": args}\n",
    "    \n",
    "    def _execute_tool(self, tool_name: str, args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a tool with given arguments\"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            return {\"success\": False, \"error\": f\"Tool '{tool_name}' not found\"}\n",
    "        \n",
    "        tool = self.tools[tool_name]\n",
    "        print(f\"  üîß Executing tool: {tool_name}\")\n",
    "        print(f\"     Args: {args}\")\n",
    "        \n",
    "        result = tool.execute(**args)\n",
    "        \n",
    "        if result.get(\"success\"):\n",
    "            print(f\"  ‚úÖ Tool succeeded in {format_time_ns(result.get('elapsed_ns', 0))}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Tool failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _llm_invoke(self, prompt: str, label: str) -> str:\n",
    "        \"\"\"Invoke LLM and track timing\"\"\"\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(f\"llm_{label}\", elapsed)\n",
    "            content = response.content if hasattr(response, 'content') else str(response)\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(f\"llm_{label}_error\", elapsed)\n",
    "            print(f\"LLM error in {label}: {e}\")\n",
    "            return str(e)\n",
    "    \n",
    "    def query(self, question: str, max_steps: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"Process a query using agentic tool selection\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ü§ñ AGENTIC RAG QUERY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"‚ùì Question: {question}\\n\")\n",
    "        \n",
    "        overall_start = time.time_ns()\n",
    "        conversation_history = []\n",
    "        tool_results = []\n",
    "        step = 0\n",
    "        \n",
    "        # Initial prompt\n",
    "        system_prompt = f\"\"\"You are an intelligent assistant with access to tools. To answer questions, you can:\n",
    "1. Use tools by writing: USE_TOOL: tool_name(arg=\"value\")\n",
    "2. Provide a final answer when you have enough information\n",
    "\n",
    "Available tools:\n",
    "{self.tool_descriptions}\n",
    "\n",
    "IMPORTANT: \n",
    "- Use ONE tool at a time\n",
    "- After using a tool, I will give you its result\n",
    "- When you have enough information, provide a FINAL ANSWER: [your answer]\n",
    "- Be strategic about which tools to use\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "What's your first action?\"\"\"\n",
    "        \n",
    "        current_prompt = system_prompt\n",
    "        \n",
    "        while step < max_steps:\n",
    "            step += 1\n",
    "            print(f\"\\n--- Step {step} ---\")\n",
    "            \n",
    "            # Get LLM decision\n",
    "            response = self._llm_invoke(current_prompt, f\"step_{step}\")\n",
    "            print(f\"üß† LLM Response:\\n{response[:500]}...\")\n",
    "            \n",
    "            # Check for final answer\n",
    "            if \"FINAL ANSWER:\" in response.upper():\n",
    "                final_answer = re.search(r'FINAL ANSWER:\\s*(.*)', response, re.IGNORECASE | re.DOTALL)\n",
    "                if final_answer:\n",
    "                    answer = final_answer.group(1).strip()\n",
    "                    print(f\"\\n‚úÖ Final answer reached at step {step}\")\n",
    "                    \n",
    "                    total_elapsed = time.time_ns() - overall_start\n",
    "                    latency_report.add(\"agentic_query_total\", total_elapsed)\n",
    "                    \n",
    "                    return {\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer,\n",
    "                        \"steps\": step,\n",
    "                        \"tool_results\": tool_results,\n",
    "                        \"total_elapsed_ns\": total_elapsed\n",
    "                    }\n",
    "            \n",
    "            # Parse and execute tool call\n",
    "            tool_call = self._parse_tool_call(response)\n",
    "            if tool_call:\n",
    "                tool_name = tool_call[\"tool\"]\n",
    "                tool_args = tool_call[\"args\"]\n",
    "                \n",
    "                # Execute tool\n",
    "                result = self._execute_tool(tool_name, tool_args)\n",
    "                tool_results.append({\n",
    "                    \"step\": step,\n",
    "                    \"tool\": tool_name,\n",
    "                    \"args\": tool_args,\n",
    "                    \"result\": result\n",
    "                })\n",
    "                \n",
    "                # Update prompt with tool result\n",
    "                if result.get(\"success\"):\n",
    "                    tool_output = result.get(\"result\", \"\")\n",
    "                    current_prompt = f\"\"\"Previous action: Used {tool_name}\n",
    "Tool result: {tool_output}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Based on this information, what's your next action? (Use another tool or provide FINAL ANSWER)\"\"\"\n",
    "                else:\n",
    "                    error_msg = result.get(\"error\", \"Unknown error\")\n",
    "                    current_prompt = f\"\"\"Previous action: Tried to use {tool_name} but it failed\n",
    "Error: {error_msg}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "What's your next action?\"\"\"\n",
    "            else:\n",
    "                # No tool call found, treat as reasoning step\n",
    "                print(\"  üí≠ No tool call detected, continuing...\")\n",
    "                current_prompt = f\"\"\"Your previous response: {response[:200]}...\n",
    "\n",
    "Remember to either:\n",
    "1. USE_TOOL: tool_name(arg=\"value\") to use a tool\n",
    "2. Provide FINAL ANSWER: [your answer] when ready\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "What's your next action?\"\"\"\n",
    "        \n",
    "        # Max steps reached\n",
    "        print(f\"\\n‚ö†Ô∏è Max steps ({max_steps}) reached without final answer\")\n",
    "        total_elapsed = time.time_ns() - overall_start\n",
    "        latency_report.add(\"agentic_query_total\", total_elapsed)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": \"Could not determine answer within step limit\",\n",
    "            \"steps\": step,\n",
    "            \"tool_results\": tool_results,\n",
    "            \"total_elapsed_ns\": total_elapsed\n",
    "        }\n",
    "\n",
    "# ---------------------------\n",
    "# PDF Processing\n",
    "# ---------------------------\n",
    "def load_and_process_pdf(path):\n",
    "    print(f\"üìÑ Loading PDF: {path}\")\n",
    "    start = time.time_ns()\n",
    "    \n",
    "    text = \"\"\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    \n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"pdf_load\", elapsed)\n",
    "    print(f\"‚úÖ Loaded {len(text)} characters in {format_time_ns(elapsed)}\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=100):\n",
    "    start = time.time_ns()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"chunking\", elapsed)\n",
    "    print(f\"üìÑ Created {len(chunks)} chunks in {format_time_ns(elapsed)}\")\n",
    "    return chunks\n",
    "\n",
    "def init_vectorstore(chunks, api_key, index_name=INDEX_NAME):\n",
    "    print(f\"üîß Initializing Pinecone...\")\n",
    "    start = time.time_ns()\n",
    "    \n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    existing = [idx.name for idx in pc.list_indexes()]\n",
    "    \n",
    "    if index_name in existing:\n",
    "        print(f\"üóëÔ∏è Deleting existing index...\")\n",
    "        pc.delete_index(index_name)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"üÜï Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    time.sleep(2)\n",
    "    \n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    vectorstore = PineconeVectorStore.from_texts(\n",
    "        texts=chunks,\n",
    "        embedding=embed_model,\n",
    "        index_name=index_name,\n",
    "        namespace=\"\",\n",
    "        metadatas=[{\"chunk_id\": i} for i in range(len(chunks))]\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"vectorstore_init\", elapsed)\n",
    "    print(f\"‚úÖ Vectorstore ready in {format_time_ns(elapsed)}\")\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"üöÄ AGENTIC RAG WITH TOOL USE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup\n",
    "    text = load_and_process_pdf(PDF_PATH)\n",
    "    chunks = chunk_text(text)\n",
    "    vectorstore = init_vectorstore(chunks, PINECONE_API_KEY)\n",
    "    \n",
    "    # Initialize LLM\n",
    "    print(\"\\nü§ñ Initializing LLM...\")\n",
    "    llm = ChatGroq(model_name=MODEL_NAME, temperature=0, groq_api_key=GROQ_API_KEY)\n",
    "    \n",
    "    # Initialize Tools\n",
    "    print(\"\\nüîß Initializing Tools...\")\n",
    "    tools = [\n",
    "        DocumentSearchTool(vectorstore),\n",
    "        CalculatorTool(),\n",
    "        SentimentAnalyzerTool(),\n",
    "        WebSearchSimulatorTool(),\n",
    "        DocumentSummaryTool(llm)\n",
    "    ]\n",
    "    \n",
    "    for tool in tools:\n",
    "        print(f\"  ‚úÖ {tool.name}: {tool.description}\")\n",
    "    \n",
    "    # Initialize Agentic RAG\n",
    "    agentic_rag = AgenticRAG(llm, tools)\n",
    "    print(\"\\n‚úÖ Agentic RAG system ready!\\n\")\n",
    "    \n",
    "    # Test Queries\n",
    "    queries = [\n",
    "        \"What are the main themes in the document?\",\n",
    "        \"What is 25 * 4 + sqrt(144)?\",\n",
    "        \"What is the capital of France?\",\n",
    "        \"Analyze the sentiment of: 'This is absolutely wonderful!'\",\n",
    "        \"Summarize the key points from the document about love\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for q in queries:\n",
    "        result = agentic_rag.query(q, max_steps=5)\n",
    "        results.append(result)\n",
    "        print(f\"\\nüìä Query completed in {format_time_ns(result['total_elapsed_ns'])}\")\n",
    "        print(f\"   Steps taken: {result['steps']}\")\n",
    "        print(f\"   Tools used: {len(result['tool_results'])}\")\n",
    "        print(f\"   Answer: {result['answer'][:200]}...\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Final report\n",
    "    latency_report.pretty_print()\n",
    "    \n",
    "    print(\"\\n‚úÖ AGENTIC RAG PIPELINE COMPLETE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
