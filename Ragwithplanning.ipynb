{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12533d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "rag_plan_and_solve.py\n",
    "RAG with Planning (Plan-and-Solve) - Creates a plan first, then executes it step by step.\n",
    "\n",
    "The system:\n",
    "1. PLAN: Breaks down the query into subtasks\n",
    "2. EXECUTE: Executes each subtask sequentially\n",
    "3. SYNTHESIZE: Combines results into final answer\n",
    "4. REFLECT: Evaluates plan quality and execution\n",
    "\n",
    "Environment variables needed:\n",
    "    PINECONE_API_KEY, GROQ_API_KEY\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "from enum import Enum\n",
    "\n",
    "import pdfplumber\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "PDF_PATH = \"Data/ECHOES OF HER LOVE.pdf\"\n",
    "INDEX_NAME = \"pinecone-planning\"\n",
    "DIM = 384\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
    "\n",
    "if PINECONE_API_KEY is None or GROQ_API_KEY is None:\n",
    "    print(\"ERROR: Set PINECONE_API_KEY and GROQ_API_KEY environment variables\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def format_time_ns(ns: int) -> str:\n",
    "    if ns < 1_000:\n",
    "        return f\"{ns} ns\"\n",
    "    if ns < 1_000_000:\n",
    "        return f\"{ns/1_000:.3f} ¬µs\"\n",
    "    if ns < 1_000_000_000:\n",
    "        return f\"{ns/1_000_000:.3f} ms\"\n",
    "    return f\"{ns/1_000_000_000:.3f} s\"\n",
    "\n",
    "class LatencyReport:\n",
    "    def __init__(self):\n",
    "        self.store = defaultdict(list)\n",
    "    \n",
    "    def add(self, component, ns):\n",
    "        self.store[component].append(ns)\n",
    "    \n",
    "    def pretty_print(self):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"LATENCY SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        for comp, vals in sorted(self.store.items()):\n",
    "            total = sum(vals)\n",
    "            avg = total // len(vals) if vals else 0\n",
    "            print(f\"\\n{comp}:\")\n",
    "            print(f\"  Count: {len(vals)}, Total: {format_time_ns(total)}, Avg: {format_time_ns(avg)}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "latency_report = LatencyReport()\n",
    "\n",
    "# ---------------------------\n",
    "# Task Types for Plan Execution\n",
    "# ---------------------------\n",
    "class TaskType(Enum):\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    ANALYZE = \"analyze\"\n",
    "    CALCULATE = \"calculate\"\n",
    "    SUMMARIZE = \"summarize\"\n",
    "    COMPARE = \"compare\"\n",
    "    SYNTHESIZE = \"synthesize\"\n",
    "\n",
    "class Task:\n",
    "    \"\"\"Represents a single task in the plan\"\"\"\n",
    "    def __init__(self, task_id: int, task_type: TaskType, description: str, \n",
    "                 dependencies: List[int] = None, parameters: Dict = None):\n",
    "        self.task_id = task_id\n",
    "        self.task_type = task_type\n",
    "        self.description = description\n",
    "        self.dependencies = dependencies or []\n",
    "        self.parameters = parameters or {}\n",
    "        self.result = None\n",
    "        self.status = \"pending\"  # pending, running, completed, failed\n",
    "        self.elapsed_ns = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Task({self.task_id}: {self.task_type.value} - {self.description})\"\n",
    "\n",
    "class Plan:\n",
    "    \"\"\"Represents the complete execution plan\"\"\"\n",
    "    def __init__(self, query: str, tasks: List[Task]):\n",
    "        self.query = query\n",
    "        self.tasks = tasks\n",
    "        self.created_at = time.time_ns()\n",
    "    \n",
    "    def get_ready_tasks(self) -> List[Task]:\n",
    "        \"\"\"Get tasks that are ready to execute (dependencies completed)\"\"\"\n",
    "        ready = []\n",
    "        for task in self.tasks:\n",
    "            if task.status != \"pending\":\n",
    "                continue\n",
    "            # Check if all dependencies are completed\n",
    "            deps_completed = all(\n",
    "                self.tasks[dep_id].status == \"completed\" \n",
    "                for dep_id in task.dependencies\n",
    "            )\n",
    "            if deps_completed:\n",
    "                ready.append(task)\n",
    "        return ready\n",
    "    \n",
    "    def is_complete(self) -> bool:\n",
    "        \"\"\"Check if all tasks are completed or failed\"\"\"\n",
    "        return all(task.status in [\"completed\", \"failed\"] for task in self.tasks)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Plan(query='{self.query}', tasks={len(self.tasks)})\"\n",
    "\n",
    "# ---------------------------\n",
    "# Plan Executor Components\n",
    "# ---------------------------\n",
    "class TaskExecutor:\n",
    "    \"\"\"Executes individual tasks based on their type\"\"\"\n",
    "    def __init__(self, vectorstore, llm):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def execute_retrieve(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a retrieval task\"\"\"\n",
    "        query = task.parameters.get(\"query\", task.description)\n",
    "        print(f\"    üîç Retrieving: {query}\")\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        docs = self.retriever.invoke(query)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"executor_retrieve\", elapsed)\n",
    "        \n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            content = getattr(doc, \"page_content\", str(doc))\n",
    "            results.append(content)\n",
    "        \n",
    "        return \"\\n\\n\".join(results)\n",
    "    \n",
    "    def execute_analyze(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute an analysis task using LLM\"\"\"\n",
    "        # Get input from dependencies or parameters\n",
    "        input_text = self._get_input_from_dependencies(task, context)\n",
    "        analysis_focus = task.parameters.get(\"focus\", \"general analysis\")\n",
    "        \n",
    "        prompt = f\"\"\"Analyze the following information with focus on: {analysis_focus}\n",
    "\n",
    "Information:\n",
    "{input_text}\n",
    "\n",
    "Provide a detailed analysis:\"\"\"\n",
    "        \n",
    "        print(f\"    üß† Analyzing: {analysis_focus}\")\n",
    "        start = time.time_ns()\n",
    "        response = self.llm.invoke(prompt)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"executor_analyze\", elapsed)\n",
    "        \n",
    "        return response.content if hasattr(response, 'content') else str(response)\n",
    "    \n",
    "    def execute_calculate(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a calculation task\"\"\"\n",
    "        calculation = task.parameters.get(\"calculation\", \"\")\n",
    "        print(f\"    üî¢ Calculating: {calculation}\")\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            # Simple calculation support\n",
    "            result = eval(calculation, {\"__builtins__\": {}}, {})\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"executor_calculate\", elapsed)\n",
    "            return f\"Calculation result: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"Calculation error: {str(e)}\"\n",
    "    \n",
    "    def execute_summarize(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a summarization task\"\"\"\n",
    "        input_text = self._get_input_from_dependencies(task, context)\n",
    "        \n",
    "        prompt = f\"\"\"Provide a concise summary of the following information:\n",
    "\n",
    "{input_text[:2000]}\n",
    "\n",
    "Summary:\"\"\"\n",
    "        \n",
    "        print(f\"    üìù Summarizing...\")\n",
    "        start = time.time_ns()\n",
    "        response = self.llm.invoke(prompt)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"executor_summarize\", elapsed)\n",
    "        \n",
    "        return response.content if hasattr(response, 'content') else str(response)\n",
    "    \n",
    "    def execute_compare(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a comparison task\"\"\"\n",
    "        input_text = self._get_input_from_dependencies(task, context)\n",
    "        comparison_aspects = task.parameters.get(\"aspects\", \"general comparison\")\n",
    "        \n",
    "        prompt = f\"\"\"Compare and contrast the following information focusing on: {comparison_aspects}\n",
    "\n",
    "Information:\n",
    "{input_text}\n",
    "\n",
    "Comparison:\"\"\"\n",
    "        \n",
    "        print(f\"    ‚öñÔ∏è Comparing: {comparison_aspects}\")\n",
    "        start = time.time_ns()\n",
    "        response = self.llm.invoke(prompt)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"executor_compare\", elapsed)\n",
    "        \n",
    "        return response.content if hasattr(response, 'content') else str(response)\n",
    "    \n",
    "    def execute_synthesize(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a synthesis task - combines multiple results\"\"\"\n",
    "        input_text = self._get_input_from_dependencies(task, context)\n",
    "        \n",
    "        prompt = f\"\"\"Synthesize the following information into a coherent, comprehensive answer:\n",
    "\n",
    "{input_text}\n",
    "\n",
    "Original Question: {context.get('original_query', '')}\n",
    "\n",
    "Synthesized Answer:\"\"\"\n",
    "        \n",
    "        print(f\"    üîÑ Synthesizing final answer...\")\n",
    "        start = time.time_ns()\n",
    "        response = self.llm.invoke(prompt)\n",
    "        elapsed = time.time_ns() - start\n",
    "        latency_report.add(\"executor_synthesize\", elapsed)\n",
    "        \n",
    "        return response.content if hasattr(response, 'content') else str(response)\n",
    "    \n",
    "    def _get_input_from_dependencies(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Get input text from task dependencies\"\"\"\n",
    "        inputs = []\n",
    "        for dep_id in task.dependencies:\n",
    "            dep_task = context['plan'].tasks[dep_id]\n",
    "            if dep_task.result:\n",
    "                inputs.append(f\"From {dep_task.description}:\\n{dep_task.result}\")\n",
    "        return \"\\n\\n\".join(inputs) if inputs else task.description\n",
    "    \n",
    "    def execute_task(self, task: Task, context: Dict) -> str:\n",
    "        \"\"\"Execute a task based on its type\"\"\"\n",
    "        task.status = \"running\"\n",
    "        start = time.time_ns()\n",
    "        \n",
    "        try:\n",
    "            if task.task_type == TaskType.RETRIEVE:\n",
    "                result = self.execute_retrieve(task, context)\n",
    "            elif task.task_type == TaskType.ANALYZE:\n",
    "                result = self.execute_analyze(task, context)\n",
    "            elif task.task_type == TaskType.CALCULATE:\n",
    "                result = self.execute_calculate(task, context)\n",
    "            elif task.task_type == TaskType.SUMMARIZE:\n",
    "                result = self.execute_summarize(task, context)\n",
    "            elif task.task_type == TaskType.COMPARE:\n",
    "                result = self.execute_compare(task, context)\n",
    "            elif task.task_type == TaskType.SYNTHESIZE:\n",
    "                result = self.execute_synthesize(task, context)\n",
    "            else:\n",
    "                result = f\"Unknown task type: {task.task_type}\"\n",
    "            \n",
    "            task.result = result\n",
    "            task.status = \"completed\"\n",
    "            task.elapsed_ns = time.time_ns() - start\n",
    "            \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            task.status = \"failed\"\n",
    "            task.elapsed_ns = time.time_ns() - start\n",
    "            task.result = f\"Error: {str(e)}\"\n",
    "            print(f\"    ‚ùå Task failed: {str(e)}\")\n",
    "            return task.result\n",
    "\n",
    "# ---------------------------\n",
    "# Plan and Solve RAG System\n",
    "# ---------------------------\n",
    "class PlanAndSolveRAG:\n",
    "    \"\"\"RAG system that creates a plan and executes it step by step\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.executor = TaskExecutor(vectorstore, llm)\n",
    "    \n",
    "    def _llm_invoke(self, prompt: str, label: str) -> str:\n",
    "        \"\"\"Invoke LLM with timing\"\"\"\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(f\"llm_{label}\", elapsed)\n",
    "            return response.content if hasattr(response, 'content') else str(response)\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(f\"llm_{label}_error\", elapsed)\n",
    "            return str(e)\n",
    "    \n",
    "    def create_plan(self, query: str) -> Plan:\n",
    "        \"\"\"Create an execution plan for the query\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìã CREATING EXECUTION PLAN\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Query: {query}\\n\")\n",
    "        \n",
    "        planning_prompt = f\"\"\"You are a planning expert. Break down this query into a step-by-step execution plan.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Create a plan with numbered steps. Each step should be one of these types:\n",
    "- RETRIEVE: Search for information in documents\n",
    "- ANALYZE: Analyze retrieved information\n",
    "- CALCULATE: Perform calculations\n",
    "- SUMMARIZE: Summarize information\n",
    "- COMPARE: Compare different pieces of information\n",
    "- SYNTHESIZE: Combine results into final answer\n",
    "\n",
    "Format each step as:\n",
    "Step X [TYPE]: Description\n",
    "Dependencies: [step numbers this depends on, or \"none\"]\n",
    "Parameters: key=value (if needed)\n",
    "\n",
    "Example:\n",
    "Step 1 [RETRIEVE]: Find information about themes\n",
    "Dependencies: none\n",
    "Parameters: query=\"main themes\"\n",
    "\n",
    "Step 2 [ANALYZE]: Analyze the themes found\n",
    "Dependencies: 1\n",
    "Parameters: focus=\"literary themes\"\n",
    "\n",
    "Step 3 [SYNTHESIZE]: Create final answer\n",
    "Dependencies: 2\n",
    "\n",
    "Now create the plan:\"\"\"\n",
    "        \n",
    "        plan_text = self._llm_invoke(planning_prompt, \"planning\")\n",
    "        print(f\"ü§ñ Generated Plan:\\n{plan_text}\\n\")\n",
    "        \n",
    "        # Parse the plan into Task objects\n",
    "        tasks = self._parse_plan(plan_text)\n",
    "        \n",
    "        if not tasks:\n",
    "            # Fallback: create a simple plan\n",
    "            print(\"‚ö†Ô∏è Could not parse plan, creating default plan\")\n",
    "            tasks = [\n",
    "                Task(0, TaskType.RETRIEVE, \"Retrieve relevant information\", [], {\"query\": query}),\n",
    "                Task(1, TaskType.SYNTHESIZE, \"Synthesize answer\", [0], {})\n",
    "            ]\n",
    "        \n",
    "        plan = Plan(query, tasks)\n",
    "        \n",
    "        print(f\"‚úÖ Plan created with {len(tasks)} tasks:\")\n",
    "        for task in tasks:\n",
    "            deps = f\" (depends on: {task.dependencies})\" if task.dependencies else \"\"\n",
    "            print(f\"  {task.task_id}. [{task.task_type.value}] {task.description}{deps}\")\n",
    "        \n",
    "        return plan\n",
    "    \n",
    "    def _parse_plan(self, plan_text: str) -> List[Task]:\n",
    "        \"\"\"Parse plan text into Task objects\"\"\"\n",
    "        tasks = []\n",
    "        current_task = None\n",
    "        \n",
    "        lines = plan_text.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Match step definition: Step X [TYPE]: Description\n",
    "            step_match = re.match(r'Step\\s+(\\d+)\\s+\\[(\\w+)\\]:\\s*(.+)', line, re.IGNORECASE)\n",
    "            if step_match:\n",
    "                task_id = int(step_match.group(1)) - 1  # 0-indexed\n",
    "                task_type_str = step_match.group(2).upper()\n",
    "                description = step_match.group(3).strip()\n",
    "                \n",
    "                # Map string to TaskType\n",
    "                task_type_map = {\n",
    "                    \"RETRIEVE\": TaskType.RETRIEVE,\n",
    "                    \"ANALYZE\": TaskType.ANALYZE,\n",
    "                    \"CALCULATE\": TaskType.CALCULATE,\n",
    "                    \"SUMMARIZE\": TaskType.SUMMARIZE,\n",
    "                    \"COMPARE\": TaskType.COMPARE,\n",
    "                    \"SYNTHESIZE\": TaskType.SYNTHESIZE\n",
    "                }\n",
    "                task_type = task_type_map.get(task_type_str, TaskType.RETRIEVE)\n",
    "                \n",
    "                current_task = Task(task_id, task_type, description)\n",
    "                tasks.append(current_task)\n",
    "            \n",
    "            # Parse dependencies\n",
    "            elif current_task and re.match(r'Dependencies?:', line, re.IGNORECASE):\n",
    "                deps_text = line.split(':', 1)[1].strip().lower()\n",
    "                if deps_text != \"none\":\n",
    "                    # Extract numbers\n",
    "                    deps = [int(d)-1 for d in re.findall(r'\\d+', deps_text)]\n",
    "                    current_task.dependencies = deps\n",
    "            \n",
    "            # Parse parameters\n",
    "            elif current_task and re.match(r'Parameters?:', line, re.IGNORECASE):\n",
    "                params_text = line.split(':', 1)[1].strip()\n",
    "                # Parse key=value pairs\n",
    "                params = {}\n",
    "                for param in re.findall(r'(\\w+)=[\"\\'\"]?([^\"\\'\",]+)[\"\\'\"]?', params_text):\n",
    "                    params[param[0]] = param[1].strip()\n",
    "                current_task.parameters = params\n",
    "        \n",
    "        return tasks\n",
    "    \n",
    "    def execute_plan(self, plan: Plan) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the plan step by step\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚öôÔ∏è EXECUTING PLAN\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        execution_start = time.time_ns()\n",
    "        context = {\n",
    "            'plan': plan,\n",
    "            'original_query': plan.query,\n",
    "            'results': {}\n",
    "        }\n",
    "        \n",
    "        step_count = 0\n",
    "        while not plan.is_complete():\n",
    "            ready_tasks = plan.get_ready_tasks()\n",
    "            \n",
    "            if not ready_tasks:\n",
    "                print(\"‚ö†Ô∏è No ready tasks but plan not complete - possible dependency issue\")\n",
    "                break\n",
    "            \n",
    "            for task in ready_tasks:\n",
    "                step_count += 1\n",
    "                print(f\"\\n  Step {step_count}: Task {task.task_id}\")\n",
    "                print(f\"  Type: {task.task_type.value}\")\n",
    "                print(f\"  Description: {task.description}\")\n",
    "                \n",
    "                result = self.executor.execute_task(task, context)\n",
    "                context['results'][task.task_id] = result\n",
    "                \n",
    "                print(f\"  ‚úÖ Completed in {format_time_ns(task.elapsed_ns)}\")\n",
    "                print(f\"  Result preview: {result[:150]}...\")\n",
    "        \n",
    "        execution_elapsed = time.time_ns() - execution_start\n",
    "        latency_report.add(\"plan_execution_total\", execution_elapsed)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Plan execution completed in {format_time_ns(execution_elapsed)}\")\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def reflect_on_execution(self, plan: Plan, context: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Reflect on the plan execution quality\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üîç REFLECTING ON EXECUTION\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Gather execution statistics\n",
    "        completed = sum(1 for t in plan.tasks if t.status == \"completed\")\n",
    "        failed = sum(1 for t in plan.tasks if t.status == \"failed\")\n",
    "        total_time = sum(t.elapsed_ns for t in plan.tasks)\n",
    "        \n",
    "        # Get final result\n",
    "        final_task = plan.tasks[-1]\n",
    "        final_answer = final_task.result if final_task.status == \"completed\" else \"No answer generated\"\n",
    "        \n",
    "        # LLM-based reflection\n",
    "        reflection_prompt = f\"\"\"Evaluate the execution of this plan:\n",
    "\n",
    "Original Query: {plan.query}\n",
    "\n",
    "Plan had {len(plan.tasks)} tasks:\n",
    "- Completed: {completed}\n",
    "- Failed: {failed}\n",
    "- Total time: {format_time_ns(total_time)}\n",
    "\n",
    "Final Answer: {final_answer[:500]}\n",
    "\n",
    "Evaluate:\n",
    "1. Plan Quality (1-10): Was the plan well-structured?\n",
    "2. Execution Success (1-10): How well was it executed?\n",
    "3. Answer Quality (1-10): How good is the final answer?\n",
    "4. Improvements: What could be improved?\n",
    "\n",
    "Evaluation:\"\"\"\n",
    "        \n",
    "        reflection = self._llm_invoke(reflection_prompt, \"reflection\")\n",
    "        \n",
    "        print(f\"üìä Execution Statistics:\")\n",
    "        print(f\"  Tasks: {len(plan.tasks)} (‚úÖ {completed}, ‚ùå {failed})\")\n",
    "        print(f\"  Total time: {format_time_ns(total_time)}\")\n",
    "        print(f\"\\nüí≠ Reflection:\\n{reflection}\\n\")\n",
    "        \n",
    "        return {\n",
    "            \"statistics\": {\n",
    "                \"total_tasks\": len(plan.tasks),\n",
    "                \"completed\": completed,\n",
    "                \"failed\": failed,\n",
    "                \"total_time_ns\": total_time\n",
    "            },\n",
    "            \"reflection\": reflection,\n",
    "            \"final_answer\": final_answer\n",
    "        }\n",
    "    \n",
    "    def query(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Main query method: Plan -> Execute -> Reflect\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üöÄ PLAN-AND-SOLVE RAG QUERY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"‚ùì Question: {question}\\n\")\n",
    "        \n",
    "        overall_start = time.time_ns()\n",
    "        \n",
    "        # Phase 1: Planning\n",
    "        plan = self.create_plan(question)\n",
    "        \n",
    "        # Phase 2: Execution\n",
    "        context = self.execute_plan(plan)\n",
    "        \n",
    "        # Phase 3: Reflection\n",
    "        reflection_result = self.reflect_on_execution(plan, context)\n",
    "        \n",
    "        overall_elapsed = time.time_ns() - overall_start\n",
    "        latency_report.add(\"query_total\", overall_elapsed)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"plan\": plan,\n",
    "            \"answer\": reflection_result[\"final_answer\"],\n",
    "            \"reflection\": reflection_result,\n",
    "            \"total_elapsed_ns\": overall_elapsed\n",
    "        }\n",
    "\n",
    "# ---------------------------\n",
    "# PDF Processing (same as original)\n",
    "# ---------------------------\n",
    "def load_and_process_pdf(path):\n",
    "    print(f\"üìÑ Loading PDF: {path}\")\n",
    "    start = time.time_ns()\n",
    "    \n",
    "    text = \"\"\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    \n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"pdf_load\", elapsed)\n",
    "    print(f\"‚úÖ Loaded {len(text)} characters in {format_time_ns(elapsed)}\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=100):\n",
    "    start = time.time_ns()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"chunking\", elapsed)\n",
    "    print(f\"üìÑ Created {len(chunks)} chunks in {format_time_ns(elapsed)}\")\n",
    "    return chunks\n",
    "\n",
    "def init_vectorstore(chunks, api_key, index_name=INDEX_NAME):\n",
    "    print(f\"üîß Initializing Pinecone...\")\n",
    "    start = time.time_ns()\n",
    "    \n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    existing = [idx.name for idx in pc.list_indexes()]\n",
    "    \n",
    "    if index_name in existing:\n",
    "        print(f\"üóëÔ∏è Deleting existing index...\")\n",
    "        pc.delete_index(index_name)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"üÜï Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    time.sleep(2)\n",
    "    \n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    vectorstore = PineconeVectorStore.from_texts(\n",
    "        texts=chunks,\n",
    "        embedding=embed_model,\n",
    "        index_name=index_name,\n",
    "        namespace=\"\",\n",
    "        metadatas=[{\"chunk_id\": i} for i in range(len(chunks))]\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"vectorstore_init\", elapsed)\n",
    "    print(f\"‚úÖ Vectorstore ready in {format_time_ns(elapsed)}\")\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"üöÄ RAG WITH PLANNING (PLAN-AND-SOLVE)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup\n",
    "    text = load_and_process_pdf(PDF_PATH)\n",
    "    chunks = chunk_text(text)\n",
    "    vectorstore = init_vectorstore(chunks, PINECONE_API_KEY)\n",
    "    \n",
    "    # Initialize LLM\n",
    "    print(\"\\nü§ñ Initializing LLM...\")\n",
    "    llm = ChatGroq(model_name=MODEL_NAME, temperature=0, groq_api_key=GROQ_API_KEY)\n",
    "    \n",
    "    # Initialize Plan-and-Solve RAG\n",
    "    plan_solve_rag = PlanAndSolveRAG(vectorstore, llm)\n",
    "    print(\"\\n‚úÖ Plan-and-Solve RAG system ready!\\n\")\n",
    "    \n",
    "    # Test Queries\n",
    "    queries = [\n",
    "        \"What are the main themes in this story and how do they relate to each other?\",\n",
    "        \"Summarize the key events and analyze their significance.\",\n",
    "        \"What is the emotional arc of the main character throughout the document?\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for q in queries:\n",
    "        result = plan_solve_rag.query(q)\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìä QUERY SUMMARY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Question: {q}\")\n",
    "        print(f\"Plan tasks: {len(result['plan'].tasks)}\")\n",
    "        print(f\"Total time: {format_time_ns(result['total_elapsed_ns'])}\")\n",
    "        print(f\"\\nFinal Answer:\\n{result['answer'][:400]}...\")\n",
    "        print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    # Final report\n",
    "    latency_report.pretty_print()\n",
    "    \n",
    "    print(\"\\n‚úÖ PLAN-AND-SOLVE RAG PIPELINE COMPLETE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
