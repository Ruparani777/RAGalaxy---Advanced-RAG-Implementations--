{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "react_rag_full.py\n",
    "ReAct RAG Pipeline with comprehensive nanosecond latency instrumentation.\n",
    "\n",
    "ReAct Framework: Thought -> Action -> Observation loop\n",
    "- Thought: Agent reasons about what to do next\n",
    "- Action: Execute retrieval, computation, or finish\n",
    "- Observation: Examine results and decide next step\n",
    "\n",
    "Use environment variables: PINECONE_API_KEY, GROQ_API_KEY\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# third-party imports\n",
    "import pdfplumber\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "PDF_PATH = \"Data/ECHOES OF HER LOVE.pdf\"\n",
    "INDEX_NAME = \"pinecone-react\"\n",
    "DIM = 384\n",
    "PINECONE_API_KEY = \"pcsk_2vzzu5_BLrivtXHdVFYt1ciSqGCHBHymoRtjqXrmVmASwgewHN6FrtpFWcJdZwbiTEJNq4\"\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
    "TARGET_NS = 200_000\n",
    "\n",
    "if GROQ_API_KEY is None:\n",
    "    print(\"ERROR: Set GROQ_API_KEY environment variable\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def format_time_ns(ns: int) -> str:\n",
    "    if ns < 1_000:\n",
    "        return f\"{ns} ns\"\n",
    "    if ns < 1_000_000:\n",
    "        return f\"{ns/1_000:.3f} ¬µs ({ns} ns)\"\n",
    "    if ns < 1_000_000_000:\n",
    "        return f\"{ns/1_000_000:.3f} ms ({ns} ns)\"\n",
    "    return f\"{ns/1_000_000_000:.3f} s ({ns} ns)\"\n",
    "\n",
    "def timed_call(fn, *args, **kwargs):\n",
    "    start = time.time_ns()\n",
    "    result = fn(*args, **kwargs)\n",
    "    elapsed = time.time_ns() - start\n",
    "    return result, elapsed\n",
    "\n",
    "def timer_ns(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time_ns()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.time_ns() - start\n",
    "        print(f\"‚è±Ô∏è {func.__name__} time: {format_time_ns(elapsed)}\")\n",
    "        wrapper.last_elapsed_ns = elapsed\n",
    "        return result\n",
    "    wrapper.last_elapsed_ns = None\n",
    "    return wrapper\n",
    "\n",
    "class LatencyReport:\n",
    "    def __init__(self):\n",
    "        self.store = defaultdict(list)\n",
    "    def add(self, component, ns):\n",
    "        self.store[component].append(ns)\n",
    "    def summary(self):\n",
    "        out = {}\n",
    "        for comp, vals in self.store.items():\n",
    "            total = sum(vals)\n",
    "            out[comp] = {\n",
    "                \"count\": len(vals),\n",
    "                \"total_ns\": total,\n",
    "                \"avg_ns\": total // len(vals) if vals else 0,\n",
    "                \"min_ns\": min(vals) if vals else 0,\n",
    "                \"max_ns\": max(vals) if vals else 0\n",
    "            }\n",
    "        return out\n",
    "    def pretty_print(self):\n",
    "        s = self.summary()\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LATENCY SUMMARY (nanoseconds)\")\n",
    "        print(\"=\"*60)\n",
    "        for comp, stats in sorted(s.items(), key=lambda p: p[0]):\n",
    "            print(f\"\\nComponent: {comp}\")\n",
    "            print(f\"  Count: {stats['count']}\")\n",
    "            print(f\"  Total: {format_time_ns(stats['total_ns'])}\")\n",
    "            print(f\"  Avg:   {format_time_ns(stats['avg_ns'])}\")\n",
    "            print(f\"  Min:   {format_time_ns(stats['min_ns'])}\")\n",
    "            print(f\"  Max:   {format_time_ns(stats['max_ns'])}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "latency_report = LatencyReport()\n",
    "\n",
    "# ---------------------------\n",
    "# PDF/Chunking/Embeddings\n",
    "# ---------------------------\n",
    "@timer_ns\n",
    "def load_pdf(path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        page_texts = []\n",
    "        for i, p in enumerate(pdf.pages):\n",
    "            start_ns = time.time_ns()\n",
    "            t = p.extract_text() or \"\"\n",
    "            elapsed = time.time_ns() - start_ns\n",
    "            latency_report.add(\"pdf_page_extract\", elapsed)\n",
    "            page_texts.append(t)\n",
    "        text = \"\\n\".join(page_texts)\n",
    "    print(f\"üìÑ Loaded PDF, total length: {len(text)} chars\")\n",
    "    return text\n",
    "\n",
    "@timer_ns\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    print(f\"üìÑ Total Chunks: {len(chunks)}\")\n",
    "    return chunks\n",
    "\n",
    "@timer_ns\n",
    "def get_embeddings_model(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    emb = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return emb\n",
    "\n",
    "def init_pinecone(api_key, index_name=INDEX_NAME, dim=DIM):\n",
    "    start = time.time_ns()\n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "    latency_report.add(\"pinecone_list_indexes\", time.time_ns() - start)\n",
    "\n",
    "    if index_name in existing_indexes:\n",
    "        print(f\"üóëÔ∏è  Deleting existing index '{index_name}'...\")\n",
    "        start = time.time_ns()\n",
    "        pc.delete_index(index_name)\n",
    "        latency_report.add(\"pinecone_delete_index\", time.time_ns() - start)\n",
    "        time.sleep(2)\n",
    "\n",
    "    print(f\"üÜï Creating index '{index_name}'...\")\n",
    "    start = time.time_ns()\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    latency_report.add(\"pinecone_create_index\", time.time_ns() - start)\n",
    "    time.sleep(2)\n",
    "    print(f\"‚úÖ Index '{index_name}' created\")\n",
    "    return pc\n",
    "\n",
    "@timer_ns\n",
    "def create_vectorstore(embed_model, chunks, index_name=INDEX_NAME):\n",
    "    start = time.time_ns()\n",
    "    vectorstore = PineconeVectorStore.from_texts(\n",
    "        texts=chunks,\n",
    "        embedding=embed_model,\n",
    "        index_name=index_name,\n",
    "        namespace=\"\",\n",
    "        metadatas=[{\"source\": f\"chunk_{i}\", \"chunk_id\": i} for i in range(len(chunks))]\n",
    "    )\n",
    "    elapsed = time.time_ns() - start\n",
    "    latency_report.add(\"pinecone_upsert_total\", elapsed)\n",
    "    print(f\"‚úÖ Created vector store with {len(chunks)} chunks\")\n",
    "    return vectorstore\n",
    "\n",
    "# ---------------------------\n",
    "# VADER Sentiment\n",
    "# ---------------------------\n",
    "class VaderSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "    def analyze(self, text):\n",
    "        scores = self.analyzer.polarity_scores(text)\n",
    "        compound = scores['compound']\n",
    "        if compound >= 0.05:\n",
    "            label = \"POSITIVE\"\n",
    "            percentage = round((compound + 1) * 50, 2)\n",
    "        elif compound <= -0.05:\n",
    "            label = \"NEGATIVE\"\n",
    "            percentage = round((1 - abs(compound)) * 50, 2)\n",
    "        else:\n",
    "            label = \"NEUTRAL\"\n",
    "            percentage = round(50 + (compound * 50), 2)\n",
    "        return {\n",
    "            'label': label,\n",
    "            'percentage': percentage,\n",
    "            'compound': compound,\n",
    "            'scores': scores\n",
    "        }\n",
    "\n",
    "def run_sentiment_benchmark(run_number, sa, examples, target_ns=TARGET_NS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî• SENTIMENT RUN #{run_number}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    individual_times = []\n",
    "    for i, text in enumerate(examples, 1):\n",
    "        start_ns = time.time_ns()\n",
    "        result = sa.analyze(text)\n",
    "        elapsed_ns = time.time_ns() - start_ns\n",
    "        latency_report.add(\"vader_per_example\", elapsed_ns)\n",
    "        individual_times.append(elapsed_ns)\n",
    "        status = \"‚úÖ\" if elapsed_ns < target_ns else \"‚ùå\"\n",
    "        print(f\"[{i:2d}] {format_time_ns(elapsed_ns):20s} {status} | {result['label']:8s} | \\\"{text}\\\"\")\n",
    "    total_ns = sum(individual_times)\n",
    "    avg_ns = total_ns // len(individual_times)\n",
    "    min_ns = min(individual_times)\n",
    "    max_ns = max(individual_times)\n",
    "    under_target = sum(1 for t in individual_times if t < target_ns)\n",
    "    print(f\"\\nüìä RUN #{run_number} STATISTICS:\")\n",
    "    print(f\"   Total:        {format_time_ns(total_ns)}\")\n",
    "    print(f\"   Average:      {format_time_ns(avg_ns)}\")\n",
    "    print(f\"   Min:          {format_time_ns(min_ns)}\")\n",
    "    print(f\"   Max:          {format_time_ns(max_ns)}\")\n",
    "    print(f\"   < {target_ns}ns: {under_target}/{len(individual_times)} texts\")\n",
    "    if avg_ns < target_ns:\n",
    "        print(f\"   ‚úÖ TARGET MET!\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  TARGET MISSED\")\n",
    "    return {\n",
    "        'run': run_number,\n",
    "        'times': individual_times,\n",
    "        'total': total_ns,\n",
    "        'avg': avg_ns,\n",
    "        'min': min_ns,\n",
    "        'max': max_ns,\n",
    "        'under_target': under_target\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# ReAct RAG Implementation\n",
    "# ---------------------------\n",
    "class ReActRAG:\n",
    "    \"\"\"\n",
    "    ReAct (Reasoning + Acting) RAG Agent\n",
    "    \n",
    "    Loop:\n",
    "    1. Thought: Reason about current state and what to do\n",
    "    2. Action: Execute action (retrieve, compute, finish)\n",
    "    3. Observation: Process results and decide next step\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm, max_steps=5):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.max_steps = max_steps\n",
    "        self.retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 4}\n",
    "        )\n",
    "        \n",
    "        # Available actions\n",
    "        self.actions = {\n",
    "            \"RETRIEVE\": self._action_retrieve,\n",
    "            \"COMPUTE\": self._action_compute,\n",
    "            \"FINISH\": self._action_finish\n",
    "        }\n",
    "    \n",
    "    def _llm_invoke_timed(self, prompt, label):\n",
    "        \"\"\"Invoke LLM with timing\"\"\"\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(label, elapsed)\n",
    "            content = response.content if hasattr(response, 'content') else str(response)\n",
    "            return content, elapsed\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(label + \"_error\", elapsed)\n",
    "            print(f\"LLM invoke for {label} failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return str(e), elapsed\n",
    "    \n",
    "    def _thought(self, question: str, history: List[Dict], step: int) -> Tuple[str, str]:\n",
    "        \"\"\"Generate reasoning about what action to take next\"\"\"\n",
    "        \n",
    "        # Build context from history\n",
    "        context = self._build_context_from_history(history)\n",
    "        \n",
    "        prompt = f\"\"\"You are a ReAct agent. Analyze the question and decide your next action.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Previous Steps:\n",
    "{context}\n",
    "\n",
    "Available Actions:\n",
    "1. RETRIEVE - Search the document for relevant information\n",
    "2. COMPUTE - Process or analyze information you have\n",
    "3. FINISH - Provide final answer when you have enough information\n",
    "\n",
    "Think step-by-step:\n",
    "- What do I know so far?\n",
    "- What information do I still need?\n",
    "- What action should I take next?\n",
    "\n",
    "Respond in this format:\n",
    "Thought: [Your reasoning here]\n",
    "Action: [RETRIEVE/COMPUTE/FINISH]\n",
    "Action Input: [Specific query or instruction]\n",
    "\n",
    "Your response:\"\"\"\n",
    "        \n",
    "        thought_text, elapsed = self._llm_invoke_timed(prompt, \"react_thought\")\n",
    "        print(f\"\\nüí≠ THOUGHT (Step {step}, {format_time_ns(elapsed)}):\")\n",
    "        print(f\"   {thought_text[:500]}...\")\n",
    "        \n",
    "        # Parse action and input\n",
    "        action, action_input = self._parse_thought(thought_text)\n",
    "        \n",
    "        return action, action_input\n",
    "    \n",
    "    def _parse_thought(self, thought_text: str) -> Tuple[str, str]:\n",
    "        \"\"\"Extract action and action input from thought\"\"\"\n",
    "        action = \"FINISH\"  # default\n",
    "        action_input = \"\"\n",
    "        \n",
    "        # Try to extract action\n",
    "        action_match = re.search(r'Action:\\s*(RETRIEVE|COMPUTE|FINISH)', thought_text, re.IGNORECASE)\n",
    "        if action_match:\n",
    "            action = action_match.group(1).upper()\n",
    "        \n",
    "        # Try to extract action input\n",
    "        input_match = re.search(r'Action Input:\\s*(.+?)(?:\\n|$)', thought_text, re.IGNORECASE | re.DOTALL)\n",
    "        if input_match:\n",
    "            action_input = input_match.group(1).strip()\n",
    "        \n",
    "        return action, action_input\n",
    "    \n",
    "    def _action_retrieve(self, query: str) -> Tuple[str, int]:\n",
    "        \"\"\"Execute retrieval action\"\"\"\n",
    "        start = time.time_ns()\n",
    "        try:\n",
    "            docs = self.retriever.invoke(query)\n",
    "            elapsed = time.time_ns() - start\n",
    "            latency_report.add(\"react_retrieve\", elapsed)\n",
    "            \n",
    "            if not docs:\n",
    "                return \"No documents found.\", elapsed\n",
    "            \n",
    "            # Extract content\n",
    "            content = \"\\n\\n\".join([\n",
    "                getattr(doc, \"page_content\", None) or getattr(doc, \"content\", None) or str(doc)\n",
    "                for doc in docs\n",
    "            ])\n",
    "            \n",
    "            result = f\"Retrieved {len(docs)} documents:\\n{content[:1000]}...\"\n",
    "            print(f\"\\nüîç RETRIEVE ACTION ({format_time_ns(elapsed)}):\")\n",
    "            print(f\"   Found {len(docs)} documents, {len(content)} chars\")\n",
    "            \n",
    "            return result, elapsed\n",
    "        except Exception as e:\n",
    "            elapsed = time.time_ns() - start\n",
    "            print(f\"Retrieval failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return f\"Error: {str(e)}\", elapsed\n",
    "    \n",
    "    def _action_compute(self, instruction: str) -> Tuple[str, int]:\n",
    "        \"\"\"Execute computation/analysis action\"\"\"\n",
    "        # Use LLM to process or analyze information\n",
    "        prompt = f\"\"\"Process the following instruction:\n",
    "\n",
    "{instruction}\n",
    "\n",
    "Provide a clear, concise analysis or computation result.\n",
    "\n",
    "Result:\"\"\"\n",
    "        \n",
    "        result, elapsed = self._llm_invoke_timed(prompt, \"react_compute\")\n",
    "        print(f\"\\nüßÆ COMPUTE ACTION ({format_time_ns(elapsed)}):\")\n",
    "        print(f\"   Result: {result[:300]}...\")\n",
    "        \n",
    "        return result, elapsed\n",
    "    \n",
    "    def _action_finish(self, final_answer: str) -> Tuple[str, int]:\n",
    "        \"\"\"Finish with final answer\"\"\"\n",
    "        start = time.time_ns()\n",
    "        print(f\"\\n‚úÖ FINISH ACTION:\")\n",
    "        print(f\"   Final answer prepared\")\n",
    "        elapsed = time.time_ns() - start\n",
    "        return final_answer, elapsed\n",
    "    \n",
    "    def _observation(self, action: str, result: str, elapsed_ns: int) -> str:\n",
    "        \"\"\"Process observation from action result\"\"\"\n",
    "        obs = f\"Observation from {action} (took {format_time_ns(elapsed_ns)}): {result[:500]}\"\n",
    "        print(f\"\\nüëÅÔ∏è OBSERVATION:\")\n",
    "        print(f\"   {obs[:300]}...\")\n",
    "        return obs\n",
    "    \n",
    "    def _build_context_from_history(self, history: List[Dict]) -> str:\n",
    "        \"\"\"Build context string from interaction history\"\"\"\n",
    "        if not history:\n",
    "            return \"No previous steps.\"\n",
    "        \n",
    "        lines = []\n",
    "        for i, step in enumerate(history, 1):\n",
    "            lines.append(f\"Step {i}:\")\n",
    "            lines.append(f\"  Thought: {step.get('thought', '')[:100]}...\")\n",
    "            lines.append(f\"  Action: {step['action']}\")\n",
    "            lines.append(f\"  Observation: {step['observation'][:100]}...\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def query(self, question: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Execute ReAct loop for answering question\n",
    "        \n",
    "        Returns:\n",
    "            Dict with answer, steps, and timing info\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ü§ñ ReAct RAG QUERY PROCESSING\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"‚ùì Question: {question}\\n\")\n",
    "        \n",
    "        overall_start = time.time_ns()\n",
    "        history = []\n",
    "        final_answer = \"\"\n",
    "        \n",
    "        for step in range(1, self.max_steps + 1):\n",
    "            step_start = time.time_ns()\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"üìç STEP {step}/{self.max_steps}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            # 1. THOUGHT: Reason about next action\n",
    "            action, action_input = self._thought(question, history, step)\n",
    "            \n",
    "            # 2. ACTION: Execute chosen action\n",
    "            if action in self.actions:\n",
    "                action_func = self.actions[action]\n",
    "                \n",
    "                if action == \"FINISH\":\n",
    "                    # Generate final answer using all context\n",
    "                    context = self._build_context_from_history(history)\n",
    "                    final_prompt = f\"\"\"Based on the following information, provide a comprehensive answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context from previous steps:\n",
    "{context}\n",
    "\n",
    "Provide a clear, detailed final answer:\"\"\"\n",
    "                    \n",
    "                    final_answer, elapsed = self._llm_invoke_timed(final_prompt, \"react_final_answer\")\n",
    "                    result = final_answer\n",
    "                else:\n",
    "                    result, elapsed = action_func(action_input)\n",
    "            else:\n",
    "                result = f\"Unknown action: {action}\"\n",
    "                elapsed = 0\n",
    "            \n",
    "            # 3. OBSERVATION: Process result\n",
    "            observation = self._observation(action, result, elapsed)\n",
    "            \n",
    "            # Record step\n",
    "            step_elapsed = time.time_ns() - step_start\n",
    "            latency_report.add(\"react_step\", step_elapsed)\n",
    "            \n",
    "            history.append({\n",
    "                'step': step,\n",
    "                'thought': f\"Action: {action}, Input: {action_input}\",\n",
    "                'action': action,\n",
    "                'action_input': action_input,\n",
    "                'observation': observation,\n",
    "                'result': result,\n",
    "                'step_time_ns': step_elapsed\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n‚è±Ô∏è Step {step} total time: {format_time_ns(step_elapsed)}\")\n",
    "            \n",
    "            # Check if we should finish\n",
    "            if action == \"FINISH\":\n",
    "                print(f\"\\n‚úÖ ReAct completed after {step} step(s)\")\n",
    "                break\n",
    "        \n",
    "        total_query_ns = time.time_ns() - overall_start\n",
    "        latency_report.add(\"react_query_total\", total_query_ns)\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': final_answer or history[-1]['result'],\n",
    "            'steps': history,\n",
    "            'total_steps': len(history),\n",
    "            'total_query_ns': total_query_ns\n",
    "        }\n",
    "\n",
    "# ---------------------------\n",
    "# Main Pipeline\n",
    "# ---------------------------\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ü§ñ ReAct RAG PIPELINE + FULL LATENCY INSTRUMENTATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_total = time.time_ns()\n",
    "    \n",
    "    # Phase 1: Setup\n",
    "    try:\n",
    "        pdf_text, t_pdf = timed_call(load_pdf, PDF_PATH)\n",
    "        latency_report.add(\"pdf_load\", t_pdf)\n",
    "        \n",
    "        chunks, t_chunks = timed_call(chunk_text, pdf_text, 1000, 100)\n",
    "        latency_report.add(\"chunking\", t_chunks)\n",
    "        \n",
    "        embed_model, t_emb = timed_call(get_embeddings_model)\n",
    "        latency_report.add(\"embedding_model_init\", t_emb)\n",
    "        \n",
    "        pc = init_pinecone(PINECONE_API_KEY, INDEX_NAME, DIM)\n",
    "        vectorstore = create_vectorstore(embed_model, chunks, INDEX_NAME)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error in Phase 1:\", e)\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Initialize LLM\n",
    "    try:\n",
    "        start_ns = time.time_ns()\n",
    "        llm = ChatGroq(model_name=MODEL_NAME, temperature=0, groq_api_key=GROQ_API_KEY)\n",
    "        elapsed_ns = time.time_ns() - start_ns\n",
    "        latency_report.add(\"llm_init\", elapsed_ns)\n",
    "        print(f\"‚úÖ LLM initialized in {format_time_ns(elapsed_ns)}\")\n",
    "    except Exception as e:\n",
    "        print(\"LLM init failed:\", e)\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Initialize ReAct RAG\n",
    "    react_rag = ReActRAG(vectorstore, llm, max_steps=5)\n",
    "    print(\"\\n‚úÖ ReAct RAG system initialized!\")\n",
    "    \n",
    "    # Phase 2: ReAct Queries\n",
    "    print(\"\\n\\nüìö PHASE 2: ReAct RAG QUERIES\")\n",
    "    queries = [\n",
    "        \"What are the main themes in this story?\",\n",
    "        \"Summarize the key events in the document.\",\n",
    "        \"What is the capital of France?\"\n",
    "    ]\n",
    "    \n",
    "    react_results = []\n",
    "    for q in queries:\n",
    "        result = react_rag.query(q)\n",
    "        react_results.append(result)\n",
    "        print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    # Phase 3: VADER Sentiment\n",
    "    print(\"\\nüìö PHASE 3: VADER SENTIMENT BENCHMARK\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"üéØ TARGET: < {TARGET_NS} ns per analysis\\n\")\n",
    "    \n",
    "    sa_start = time.time_ns()\n",
    "    sa = VaderSentimentAnalyzer()\n",
    "    sa_init_ns = time.time_ns() - sa_start\n",
    "    latency_report.add(\"vader_init\", sa_init_ns)\n",
    "    print(f\"‚úÖ VADER INIT TIME: {format_time_ns(sa_init_ns)}\\n\")\n",
    "    \n",
    "    examples = [\n",
    "        \"I love this product!\",\n",
    "        \"This is very bad service.\",\n",
    "        \"It's okay, not too good, not too bad.\",\n",
    "        \"Not great, really disappointed\",\n",
    "        \"Amazing experience!\"\n",
    "    ]\n",
    "    \n",
    "    for run in range(1, 4):\n",
    "        run_sentiment_benchmark(run, sa, examples, TARGET_NS)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    # Final Report\n",
    "    overall_ns = time.time_ns() - start_total\n",
    "    latency_report.add(\"pipeline_total\", overall_ns)\n",
    "    \n",
    "    print(\"\\nüìà FINAL RESULTS\")\n",
    "    print(f\"   Full pipeline time: {format_time_ns(overall_ns)}\")\n",
    "    print(f\"   Queries executed: {len(queries)}\")\n",
    "    \n",
    "    latency_report.pretty_print()\n",
    "    \n",
    "    print(\"\\nSample ReAct Results:\")\n",
    "    for r in react_results:\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Q: {r['question']}\")\n",
    "        print(f\"A: {r['answer'][:500]}...\")\n",
    "        print(f\"Steps: {r['total_steps']}, Time: {format_time_ns(r['total_query_ns'])}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ReAct PIPELINE COMPLETE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
